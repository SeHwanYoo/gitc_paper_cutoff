{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Image Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASS = 10 \n",
    "RES_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.concatenate([x_train, x_test])\n",
    "y_data = np.concatenate([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = np.unique(y_train)\n",
    "# y_train\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = 32  # Resize the input images.\n",
    "representation_dim = 512  # The dimensions of the features vector.\n",
    "projection_units = 128  # The projection head of the representation learner.\n",
    "num_clusters = 20  # Number of clusters.\n",
    "k_neighbours = 5  # Number of neighbours to consider during cluster learning.\n",
    "tune_encoder_during_clustering = False  # Freeze the encoder in the cluster learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessing = tf.keras.Sequential(\n",
    "    [\n",
    "    tf.keras.layers.Resizing(RES_SIZE, RES_SIZE), \n",
    "    tf.keras.layers.Normalization()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# print(data_preprocessing.layers[-1])\n",
    "data_preprocessing.layers[-1].adapt(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomTranslation(\n",
    "            height_factor=(-0.2, 0.2), \n",
    "            width_factor=(-0.2, 0.2), \n",
    "            fill_mode='nearest'\n",
    "        ),\n",
    "        tf.keras.layers.RandomFlip(mode='horizontal'), \n",
    "        tf.keras.layers.RandomRotation(factor=0.15, fill_mode='nearest'), \n",
    "        tf.keras.layers.RandomZoom(\n",
    "            height_factor=(-0.3, 0.1), width_factor=(-0.3, 0.1), fill_mode='nearest'\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALEAAADBCAYAAACAC1EEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUmUlEQVR4nO2dSYxc13WG/1tzva6qrqoe2M1usilxkKjBUgJKsgLJlryILQPxJt7YC2fhreKlswngLBIgWWSXYZcBcewsMsCw4QCJIkVyRIiSLYoR2dRAUmyyySbZ3dVVXfOr4WVBBSDy/68iM1IaVzofIEA4rKp7332nL97/zrnnuCiKYBg+k9jrCRjG/xVzYsN7zIkN7zEnNrzHnNjwHnNiw3vMie8S59x9zrm3nHNN59x39no+n2VSez0Bj/kugJeiKHp0ryfyWcd24rtnBcA59Q/OueT/81w+05gT3wXOuRcBPAvgT5xzLefcD5xzf+6c+6lzrg3gWefccefcvzvn6s65c865r93x/Rnn3I+dc7vOuTecc7/vnPuPPbsgzzEnvguiKPoSgJ8BeD6KogKAEMA3AfwBgCKAUwB+DOBfAMwD+G0Af+ucu+/Dn/hTAG0ACwB+68P/jLvEnPjj40dRFL0aRdEYwKMACgD+MIqiMIqiFwH8BMA3PnzU+E0A34uiqBNF0SqAv96zWX8KMCf++Lh6x//vB3D1Q4f+b9YALAGYw21BfTXmu8YviTnxx8ed6YDXARxwzt25vgcBXAOwCWAIYPmOfzvwyU/v04s58SfDKQAdAN91zqWdc88A+A0AfxdF0QjAPwL4Pedc4Jy7H8C39mymnwLMiT8BoigKcdtpnwOwBeDPAHwriqJ3PvzI8wCmAdwA8DcAfgigvwdT/VTgLCl+73HO/RGAhSiK7C3FXWA78R7gnLvfOfc5d5vHAXwbwD/t9bx8xcLOe0MRtx8h9gO4CeCPAfxoT2fkMfY4YXiPPU4Y3mNObHjPxGfi7/3u79CzxrVr1+hz8pHEib8P5/QkkvzZYCpPtrDXJVsCPLaaTzqdFlPk+fQGQznHZJIT06rVGbI1m02y5bM5snXaHbLV63WyqWtpd9tyjmrJg6BItsIU2xIpXotwxGsx7Ir1HvTYNuJ7BQDhUK0vjz0ej8j2g7//qXQg24kN7zEnNrzHnNjwnonPxNlslmylUols3a54VnX807kc/x4AjCN+pkLEz4yZTEi26nSZxxbPr8PBgGyNXX5+zST0kozE82G3WSNbSjzfTRULZIvE4Y+mWMd0iueTzQRyjhiPyZQPMjyfAt+HsePvpsesI4Zi2xuFPEcHHhcAphL8A+mMGCdGmyhsJza8x5zY8B5zYsN7zIkN75ko7NSL+3K5TDYVCMim+MH++P1H5TjDcYtsA2HLiNlGQxYkjd0G2xr8e8Nwl8fIcCAA0EGV1u4m2ZwQhmMRhRiOxXv7iF/wD8T1pYVoBoCUuA+5NNv276uSbbfNa7HdYKGZSrIojMS9TgpBCgBBwKJU2UYjXos4bCc2vMec2PAec2LDe8yJDe+ZKOw6HY6aqSheJsMP9tNFzkJbXmZBAQDF0iLZ2p06j5Pmv7mL779Htu3NDbKpRLtqmSNpCacjTQmRgVcbsvDpdFggbbX5c4VSmWxBlq8vDDlKmUlq0ZMR0bDqNF/joeV5siXSS2R7+/wlsm1ucXR1JBY3JcQeAOQLLJyDYIpsAxFhjcN2YsN7zIkN7zEnNrzHnNjwnonCTqUf7u6ycFFir1ji9LpOhyNcANDr899Sp81HcHYbdbJdWfuAbOOhOi7FplSGo1njgS7EMxJpjqkEC6xcmgcaDkWqaSjSQHMshkfimE+xwJ8DgOki34dKmQVWVtz16WqZbPvmZ8nWbPE9HIkIYibL9x8AkklhVxHNEa93HLYTG95jTmx4jzmx4T3mxIb3mBMb3jPx7US3yyHPsM9Ku5Avk21+jsOdt26ty3HUocChCLfWtutka+2K0HhGHIQUbxdEfQ6MRU4vAIyGHAYdidBoWuT0qpcJqTSPEw34jQVGvN6ZmFzdVIrn02ntkO2aaK7Q6/NbkJx4kVDIi0O4Ym3javz1RAGc4ZDXot3kt2Bx2E5seI85seE95sSG95gTG94zuVK8qFKTBIuwY4c5P3Uqx9/ttXXL44yoTtkdsGBzEY+dz3MuqjqkqELjQyHWxjFdmVNJDt/mMjx2U4TlM1n+0dl5rqi5vb1Ntl6f59iMET0DETJ3Ee9Tta0tstXrXM1o3/Ihsqkw9hgs7JpdXcFnKFICum0Wr/XtW/L7CtuJDe8xJza8x5zY8B5zYsN7Jgq7hDh4GOTFAdAlPuiZVOXzw5gojqg+MxSfrTc4ojVIcFhprsRCE+JaMqKkUDamAtCwy6Jp0GPb7Nwc2ZIZvpYg4BYI/T5HKTsdjnCp3GYACENxuFIIuyDP15gTLRAGI/69IGCBnA34APCNTY4UAkA44vs1ENFCVS44DtuJDe8xJza8x5zY8B5zYsN7Jgq7SqVCtn0zXIYzK/q07exwBGinpiNNOyI6k0uJlMbSNNkGKRYK2QLPcSj6p6nedrmMPoQZgiOIvS5HmpKiJx8iFrlbWyx8VCWlubl9/HNCcAFAMsFrNhjx2KWyEJ9Zjj6+d/EC2ZYPHCRbucLRx4E4CAsA2WCBbKkKr/nmDe6XGIftxIb3mBMb3mNObHiPObHhPROFXS7Hgk31hVBiRgmpsK+r68xUOeJTCvhhvyf6OIQi7VI1MMwJ0ZROc/Qpl2aBAwCZlEjlDPl66jVOc1TrMwh5fWSTxYijc6rBOAAEUzz3cMj3y6X5/OMQ/LlrGyw+h0IoHldNNsf6XjtRIrcomlXmRTWkOGwnNrzHnNjwHnNiw3vMiQ3vmSjsQlEcZDjkB3MlAF2CBUlWnLsDgGqlxGN3RIPGkNPzHFgMTQcsFCCaKWZElKpS3S/n2GnVyTYSJVv7IUf2BqIITaHA15wS0UcnzjlmRINFAMhl+D6k87wWF69yeda2mOM774piNyK188Sv8DouzHFZWABojdjlVDPPfJ6vJQ7biQ3vMSc2vMec2PAec2LDeyYKu/l5Pqs27tXJNhhwJK3T5Z4biaQ+G9bt8We3REPFcokjVY2WSLEUDTqKoglgOivSStO6ieBYRJDKFY40RmMWw1nRp0LNRxVzaTWFwBXrBQAdIc7GolJmX0QLX//5W2SrN3jse+89SrZ8joVdbdyQc1RRUrWXZkR6bxy2ExveY05seI85seE95sSG90wUdqpT+sXrfB6u1uDI1cIid22/8O5FOc7C/CGy5UWBj7YoJNLpcfRp3OOoWSgqN0I0/Bv3+bsAEIniK2GPrzsr5p0WaaCqZmQpYKHpOjyfjVB0lgRwU7R+OHqMz8StJFmkrq9fIdv9R/gerhzi39sR4+52tIgvzpTJFolSpLmAI5px2E5seI85seE95sSG95gTG95jTmx4z8S3Excv8tuEzS2u7LPb4rcGSwsiRCzCmADgHIciZ+dYGe9ceIdsMxWuCtQQFYU2Qg6Nl2a5Gk0+rcvPOhE6Hojc2v6Iv98SPTJGoinhkujjsbvD4du1Db4HAHDwyINky4tDpVNFXrNnn3mGbIE4rDsQOeZn3j5LtkxO5XQDc8vikOuI17FU4upTcdhObHiPObHhPebEhveYExveM1HYdVVH9AEHTNfWuG373Mz9ZOv3ON8VAFotLvk6M8PCzolIZko0cgzEIcxOm+fdEv0jxuKAKwCMRM60E+VnOx2+xiDH8wmqXLJ1KC5wVGKheKjMPVIAoDDFgg2i3GtW9F2ZmePQ+M0bLJBfffUk2U6dOkW2E489Lud4/BHRvyTP4fZ+T1c5UthObHiPObHhPebEhveYExveM1HYDYcsUlTDwLXLXCnm6ScfI1uhIIQHgI0N7s9w9Ohhss3MsBhy4mBmIA5CdlIsUgeixGk40k0AGw2OkuXyqhoSi6ZMkkVTt8dzLM1z1ZzDR+4j2+KsaDYJ4P3V82QLRYndbp2jgGfPrpLtjddPk+30aba125xPHJTel3P8NbGOpf3sF7mcKHMbg+3EhveYExveY05seI85seE9k0u7hnwQMgi42svq6rtku3KFK/gcP/6AHOeVn71Etlu3OH2xVGZhl85yROr86jmyhUMV7mPTrqi4AwA5EVVaOcBlYHMZjgK2Glyx59Z2nWyZLIvCfp/nffHSmpzje+9f4nE2+SDt5cuXyXb6zTNk29zke5DNskhNZfmaO1194HZri6OAi3PL/JuizG0cthMb3mNObHiPObHhPebEhvdMFHYq91F1gnfib+Gv/vL7ZPvO89+Wwxw5ci/Zrl27TraVIw+TrSs62Kuzb7Xtm2QLyjyXQAgXALhnhcXHfJUjTWGXhWFfiM/piqgUJAr7XLnAYu2VV16Rczz9JkfTmkKo9vqi14ioZhRFnDaZSPEkD68cItvSMq8XAHTE+uw2OYKYF/1H4rCd2PAec2LDe8yJDe8xJza8Z6KwGw/FuTLHfj8zx6mB587+J9n+4vs/lON8/etfI1tDFA35YO0DsiVF075LIjX08mUuXXroXr78AyIKBwCz09yfYywimls3WEDWWk2yVUXhloE403jp/Qtke+3ka3KOmyI6lxAlaZVNkcnw+hw9zCmyT3z+CbLlRZlaAHCin8rmJq/Z4oI+R6iwndjwHnNiw3vMiQ3vMSc2vGeisKtMl8lWKPC5tFqNz00df4Sja7946005zuLBFbI98/STZLt6lYu0vPbCL8j2wSUWcZ02n8WrbXOKZC4mBbBW5SqNsxVeiytrPPb6Bqel3nuUo2FbNY5mvfhvIk1VFDUBAKXXohGL85EQ7NUKX9/jT3ABlC9+4QtkG4gmko0Gi1kAcAl2uWZzh2xTU6ppo8Z2YsN7zIkN7zEnNrzHnNjwnonC7rCIzty6xaLCOY7CTAkBeOy+Y3Kc8+f5jF5BROKWljia9vDDn+P5iMtaXmLx+MILL5Lt3CpHGgHgsRN8PrBY4jm6JAu2V15+g2yvnuRzgJs1Fjgb4pzb/BwXWQGAZJJTPqtCkJbLZbIdPMhNFp966imyzcxwS4bVVS68olI7AaAyy2OnUny/trf5uuOwndjwHnNiw3vMiQ3vMSc2vMec2PCeiW8nWi0Og45EGHNqiqsCtUQFmOmYBnu5DKvqGyK0eubM22T78leeI9tXn/sq2cZjfmtQKHLO640NXV2ntsPz6XdZQS8uzpEtk+JxVt/h3OiiODx64sSvku3Y0aNyjtmMaGo5y28y5uc5/3tLNIxUtt1d7q+ibMMRl5QFgE6Hw9HqTZbq4xKH7cSG95gTG95jTmx4jzmx4T0ThZ16sFdVYQIh7GaF7eYt3egwJw4kdpp1suVFH4eTJ18n26OPcih6cT8fzFxYYBFW2+LKQwCwKUrNZhZZqO7bx+N8/kk+SFmcZsFVEPnJB+7hcHBOlIAFgNkZ/k2VElCv18nWE2Fi9Tkl7BXsJbep7WyTrS8O3I7H2lcUthMb3mNObHiPObHhPebEhvf8Lz07uPGisinxUBYiY2pKd07viuhMMskHNpeXONKUFmJv9Tw3Jaw3WJg99NBDZBuEWpJcv8YRu5XlJbJ12n2yLS8LwSVKpA6Elkk4jmb2ujwGoA/sptO8jkqwq5K9/T6PMxTNHdUYi/t1BZ++OFSq5p1K8XXHYTux4T3mxIb3mBMb3mNObHjPRGGnojiqLGivxwJge4sjM1nRgR4AnGjwWC1x48WFRT4o2hYiR1XCWV/n1Mfpae650Wxp0fTuO1zZ58Hjx8k2W2XxWp0VVZOaLGaSQ3E7EiyanGruAaBUKvFnhej+qPdV2fJ5fQ//J0ooAkBXROcyooFl3PcVthMb3mNObHiPObHhPebEhvdMFHb7Fzkitb3Ngq3b5V4T6kzbEVFRCABmqtwP49bNG2zb5LGVAFCRwVKRo2atFkcfs1O618R2g3uInH6bI4PPfeVLPJ9pFnaVKouwdIptyRSL3l5fn1/LiapJ2Syfu1Nn7FSKpRKFKmKnBOD6Ve6bAgCjMY8zO8cpsTNVrjQUh+3EhveYExveY05seI85seE9E4Xd008/Tbbr1/kMmkrtU+LqgQcelOOo4isOnIp3+TJH3fohR9gGA073m57m83DquNhACBcAOHKMC5asX2fxubHBKZv5KV7mQoFF3IGlI2RrNFg0XxNjALq0qyqAo86vKcGmSq4qIa0+p85ixn0f4iVAT7wsiMN2YsN7zIkN7zEnNrzHnNjwnonCTkXiFhf57FRFNPKrlEUUZoYjRYDuA1Kr8bm7hQVOxeyH3FBxfZ2bNioxo6RHXM2OfJ7FZ6PLaYWnT3PPj1//8hfJlkqKlEbHe4oSawuLXKDl9vc5wqYiduvrHE3b2eF+ISoSp9JXlShsiAgnoEWgukZ1ljMO24kN7zEnNrzHnNjwHnNiw3smCruXX36ZbOqMlXoIL5c59bFS1ul1SmBtCrGXEmfLlpb4LN7y8jLZzouCKv2QI3v9GEExEJHBYoGjko06C9JLF/l83nFxPm8q4CjeSy/+A9m6MamYDz3yCNk6bRa+KsVSCS6VnqkigErYqXN8gI7kqeIrSuzFYTux4T3mxIb3mBMb3mNObHiPObHhPb90M0bVeE+FJ1XYce3KJTlOYYoPUirFOmzz24RsjlVsuVz+SHNU6ntpiXtkAMB4xGO3GxyqDbKcL3vmrbNku3DhMtkeEG8sjh3jHOOf/PO/6jkKW7Eo3qCIe6PC8h/Vpt5OqfUG9NuttniDonwvDtuJDe8xJza8x5zY8B5zYsN7Jgq7guh+HgRcIafZ5M7pSVWlNOZPJopYNIlWFfJk59bW5keajxKKCwucl3vPYd3BvrlbJ9t6n0OrkRA+lQrnVivhc+bM22R77LETZFtZ0eJzMPxookuFmJVgU4c6q6IyT6vF661y0QFdflatRdz3FbYTG95jTmx4jzmx4T3mxIb3TBR2QcDRlUhm/7ItlVJ9GPRwqbSwi2HyORUZ5MjOaNQhWy7HZU9Vr4grazqqqPKJFaHIrR0K0aTWdvngIR53xAuRiMm1HYc8toqGKcGWFrZEQhzqTPE6LiyWydZscjQTAIYDFpqlEkcVs1m+N3HYTmx4jzmx4T3mxIb3mBMb3uPiSnAahi/YTmx4jzmx4T3mxIb3mBMb3mNObHiPObHhPf8Fx8MfzwmuPlgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_idx = np.random.choice(range(x_data.shape[0]))\n",
    "image = x_data[image_idx]\n",
    "image_class = classes[y_data[image_idx][0]]\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(x_data[image_idx].astype('uint8'))\n",
    "plt.title(image_class)\n",
    "\n",
    "_ = plt.axis('off')\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder(representation_dim): \n",
    "    encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.applications.ResNet50V2(\n",
    "                include_top=False, weights=None, pooling='avg'\n",
    "            ), \n",
    "            tf.keras.layers.Dense(representation_dim)\n",
    "            \n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepresentationLearner(tf.keras.Model):\n",
    "    def __init__(self, encoder, projection_units, num_agumentation, temperature=1.0, dropout_rate=0.1, l2_normlization=False, **kwargs):\n",
    "        \n",
    "        super(RepresentationLearner, self).__init__(**kwargs) \n",
    "        self.encoder = encoder\n",
    "        \n",
    "        self.projector = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dropout(dropout_rate), \n",
    "                tf.keras.layers.Dense(units=projection_units, use_bias=False), \n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.ReLU()\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.num_agumentation = num_agumentation\n",
    "        self.temperature = temperature \n",
    "        self.l2_normlization = l2_normlization \n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def metrics(self): \n",
    "        return [self.loss_tracker]\n",
    "    \n",
    "    def compute_contrastive_loss(self, feature_vectors, batch_size): \n",
    "        num_augmentations = tf.shape(feature_vectors)[0] // batch_size\n",
    "        \n",
    "        if self.l2_normlization:\n",
    "            feature_vectors = tf.math.l2_normalize(feature_vectors, -1)\n",
    "            \n",
    "        logits = (\n",
    "            tf.linalg.matmul(feature_vectors, feature_vectors, transpose_b = True) / self.temperature\n",
    "        )\n",
    "        \n",
    "        logits_max = tf.math.reduce_max(logits, axis=1)\n",
    "        \n",
    "        targets = tf.tile(tf.eye(batch_size), [num_augmentations, num_augmentations])\n",
    "        \n",
    "        return tf.keras.losses.categorical_crossentropy(\n",
    "            y_true=targets, y_pred=logits, from_logits=True\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        preprocessed = data_preprocessing(inputs)\n",
    "        \n",
    "        augmented = [] \n",
    "        \n",
    "        for _ in range(self.num_agumentation): \n",
    "            augmented.append(data_augmentation(preprocessed))\n",
    "            \n",
    "        augmented = tf.keras.layers.Concatenate(axis=0)(augmented)\n",
    "        \n",
    "        features = self.encoder(augmented)\n",
    "        \n",
    "        return self.projector(features)\n",
    "    \n",
    "    def train_step(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            feature_vectors = self(inputs, training=True) \n",
    "            loss = self.compute_contrastive_loss(feature_vectors, batch_size)\n",
    "            \n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        \n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        feature_vectors = self(inputs, training=False) \n",
    "        loss = self.compute_contrastive_loss(feature_vectors, batch_size)    \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        \n",
    "        return {'loss' : self.loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "118/118 [==============================] - 48s 265ms/step - loss: 263.2459\n",
      "Epoch 2/50\n",
      "118/118 [==============================] - 29s 249ms/step - loss: 420.4306\n",
      "Epoch 3/50\n",
      "118/118 [==============================] - 30s 256ms/step - loss: 449.9218\n",
      "Epoch 4/50\n",
      "118/118 [==============================] - 30s 253ms/step - loss: 374.3980\n",
      "Epoch 5/50\n",
      "118/118 [==============================] - 30s 253ms/step - loss: 330.7078\n",
      "Epoch 6/50\n",
      "118/118 [==============================] - 30s 252ms/step - loss: 305.4851\n",
      "Epoch 7/50\n",
      "118/118 [==============================] - 29s 247ms/step - loss: 298.2275\n",
      "Epoch 8/50\n",
      "118/118 [==============================] - 30s 255ms/step - loss: 294.8601\n",
      "Epoch 9/50\n",
      "118/118 [==============================] - 30s 255ms/step - loss: 284.5606\n",
      "Epoch 10/50\n",
      "118/118 [==============================] - 30s 255ms/step - loss: 254.2688\n",
      "Epoch 11/50\n",
      "118/118 [==============================] - 30s 255ms/step - loss: 279.0839\n",
      "Epoch 12/50\n",
      "118/118 [==============================] - 30s 255ms/step - loss: 266.0429\n",
      "Epoch 13/50\n",
      "118/118 [==============================] - 30s 257ms/step - loss: 261.3124\n",
      "Epoch 14/50\n",
      "118/118 [==============================] - 31s 262ms/step - loss: 296.3313\n",
      "Epoch 15/50\n",
      "118/118 [==============================] - 30s 253ms/step - loss: 263.4849\n",
      "Epoch 16/50\n",
      "118/118 [==============================] - 28s 241ms/step - loss: 250.1983\n",
      "Epoch 17/50\n",
      "118/118 [==============================] - 28s 241ms/step - loss: 256.4037\n",
      "Epoch 18/50\n",
      "118/118 [==============================] - 28s 240ms/step - loss: 265.7099\n",
      "Epoch 19/50\n",
      "118/118 [==============================] - 28s 240ms/step - loss: 246.0090\n",
      "Epoch 20/50\n",
      "118/118 [==============================] - 28s 240ms/step - loss: 239.1646\n",
      "Epoch 21/50\n",
      "118/118 [==============================] - 28s 240ms/step - loss: 282.6216\n",
      "Epoch 22/50\n",
      "118/118 [==============================] - 28s 240ms/step - loss: 258.1133\n",
      "Epoch 23/50\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 357.8999\n",
      "Epoch 24/50\n",
      "118/118 [==============================] - 28s 241ms/step - loss: 318.8250\n",
      "Epoch 25/50\n",
      "118/118 [==============================] - 28s 240ms/step - loss: 311.9862\n",
      "Epoch 26/50\n",
      "118/118 [==============================] - 28s 241ms/step - loss: 349.2750\n",
      "Epoch 27/50\n",
      "118/118 [==============================] - 29s 242ms/step - loss: 353.3261\n",
      "Epoch 28/50\n",
      "118/118 [==============================] - 28s 236ms/step - loss: 366.9262\n",
      "Epoch 29/50\n",
      "118/118 [==============================] - 28s 239ms/step - loss: 323.6879\n",
      "Epoch 30/50\n",
      "118/118 [==============================] - 29s 242ms/step - loss: 271.1947\n",
      "Epoch 31/50\n",
      "118/118 [==============================] - 31s 264ms/step - loss: 233.9179\n",
      "Epoch 32/50\n",
      "118/118 [==============================] - 31s 264ms/step - loss: 204.5426\n",
      "Epoch 33/50\n",
      "118/118 [==============================] - 31s 264ms/step - loss: 203.7789\n",
      "Epoch 34/50\n",
      "118/118 [==============================] - 31s 261ms/step - loss: 216.5177\n",
      "Epoch 35/50\n",
      "118/118 [==============================] - 29s 250ms/step - loss: 219.3607\n",
      "Epoch 36/50\n",
      "118/118 [==============================] - 30s 251ms/step - loss: 287.4242\n",
      "Epoch 37/50\n",
      "118/118 [==============================] - 30s 253ms/step - loss: 240.3259\n",
      "Epoch 38/50\n",
      "118/118 [==============================] - 31s 260ms/step - loss: 207.3851\n",
      "Epoch 39/50\n",
      "118/118 [==============================] - 31s 260ms/step - loss: 221.1509\n",
      "Epoch 40/50\n",
      "118/118 [==============================] - 30s 255ms/step - loss: 213.4778\n",
      "Epoch 41/50\n",
      "118/118 [==============================] - 30s 254ms/step - loss: 198.6889\n",
      "Epoch 42/50\n",
      "118/118 [==============================] - 29s 248ms/step - loss: 189.2024\n",
      "Epoch 43/50\n",
      "118/118 [==============================] - 30s 253ms/step - loss: 191.1307\n",
      "Epoch 44/50\n",
      "118/118 [==============================] - 30s 251ms/step - loss: 217.9225\n",
      "Epoch 45/50\n",
      "118/118 [==============================] - 30s 252ms/step - loss: 209.6320\n",
      "Epoch 46/50\n",
      "118/118 [==============================] - 30s 253ms/step - loss: 198.8671\n",
      "Epoch 47/50\n",
      "118/118 [==============================] - 29s 249ms/step - loss: 198.6168\n",
      "Epoch 48/50\n",
      "118/118 [==============================] - 30s 251ms/step - loss: 179.4646\n",
      "Epoch 49/50\n",
      "118/118 [==============================] - 29s 249ms/step - loss: 180.9624\n",
      "Epoch 50/50\n",
      "118/118 [==============================] - 30s 251ms/step - loss: 177.7951\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder(representation_dim)\n",
    "\n",
    "representation_learner = RepresentationLearner(\n",
    "    encoder, projection_units, num_agumentation=2, temperature=0.1\n",
    ")\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=0.001, decay_steps=500, alpha=0.1\n",
    ")\n",
    "\n",
    "representation_learner.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=lr_schedule,\n",
    "                                   weight_decay=0.0001)\n",
    ")\n",
    "\n",
    "hist = representation_learner.fit(\n",
    "    x = x_data, \n",
    "    batch_size=512, \n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ad7f8df95050390ccef3c53b91cc5366ee05cbbc975f965dd0a4e5b2556ae66"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
