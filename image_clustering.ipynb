{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Image Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASS = 10 \n",
    "RES_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.concatenate([x_train, x_test])\n",
    "y_data = np.concatenate([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = np.unique(y_train)\n",
    "# y_train\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = 32  # Resize the input images.\n",
    "representation_dim = 512  # The dimensions of the features vector.\n",
    "projection_units = 128  # The projection head of the representation learner.\n",
    "num_clusters = 20  # Number of clusters.\n",
    "k_neighbours = 5  # Number of neighbours to consider during cluster learning.\n",
    "tune_encoder_during_clustering = False  # Freeze the encoder in the cluster learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessing = tf.keras.Sequential(\n",
    "    [\n",
    "    tf.keras.layers.Resizing(RES_SIZE, RES_SIZE), \n",
    "    tf.keras.layers.Normalization()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# print(data_preprocessing.layers[-1])\n",
    "data_preprocessing.layers[-1].adapt(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomTranslation(\n",
    "            height_factor=(-0.2, 0.2), \n",
    "            width_factor=(-0.2, 0.2), \n",
    "            fill_mode='nearest'\n",
    "        ),\n",
    "        tf.keras.layers.RandomFlip(mode='horizontal'), \n",
    "        tf.keras.layers.RandomRotation(factor=0.15, fill_mode='nearest'), \n",
    "        tf.keras.layers.RandomZoom(\n",
    "            height_factor=(-0.3, 0.1), width_factor=(-0.3, 0.1), fill_mode='nearest'\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_idx = np.random.choice(range(x_data.shape[0]))\n",
    "image = x_data[image_idx]\n",
    "image_class = classes[y_data[image_idx][0]]\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(x_data[image_idx].astype('uint8'))\n",
    "plt.title(image_class)\n",
    "\n",
    "_ = plt.axis('off')\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder(representation_dim): \n",
    "    encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.applications.ResNet50V2(\n",
    "                include_top=False, weights=None, pooling='avg'\n",
    "            ), \n",
    "            tf.keras.layers.Dense(representation_dim)\n",
    "            \n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepresentationLearner(tf.keras.Model):\n",
    "    def __init__(self, encoder, projection_units, num_agumentation, temperature=1.0, dropout_rate=0.1, l2_normlization=False, **kwargs):\n",
    "        \n",
    "        super(RepresentationLearner, self).__init__(**kwargs) \n",
    "        self.encoder = encoder\n",
    "        \n",
    "        self.projector = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dropout(dropout_rate), \n",
    "                tf.keras.layers.Dense(units=projection_units, use_bias=False), \n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.ReLU()\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.num_agumentation = num_agumentation\n",
    "        self.temperature = temperature \n",
    "        self.l2_normlization = l2_normlization \n",
    "        self.loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def metrics(self): \n",
    "        return [self.loss_tracker]\n",
    "    \n",
    "    def compute_contrastive_loss(self, feature_vectors, batch_size): \n",
    "        num_augmentations = tf.shape(feature_vectors)[0] // batch_size\n",
    "        \n",
    "        if self.l2_normlization:\n",
    "            feature_vectors = tf.math.l2_normalize(feature_vectors, -1)\n",
    "            \n",
    "        logits = (\n",
    "            tf.linalg.matmul(feature_vectors, feature_vectors, transpose_b = True) / self.temperature\n",
    "        )\n",
    "        \n",
    "        logits_max = tf.math.reduce_max(logits, axis=1)\n",
    "        \n",
    "        targets = tf.tile(tf.eye(batch_size), [num_augmentations, num_augmentations])\n",
    "        \n",
    "        return tf.keras.losses.categorical_crossentropy(\n",
    "            y_true=targets, y_pred=logits, from_logits=True\n",
    "        )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        preprocessed = data_preprocessing(inputs)\n",
    "        \n",
    "        augmented = [] \n",
    "        \n",
    "        for _ in range(self.num_agumentation): \n",
    "            augmented.append(data_augmentation(preprocessed))\n",
    "            \n",
    "        augmented = tf.keras.layers.Concatenate(axis=0)(augmented)\n",
    "        \n",
    "        features = self.encoder(augmented)\n",
    "        \n",
    "        return self.projector(features)\n",
    "    \n",
    "    def train_step(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            feature_vectors = self(inputs, training=True) \n",
    "            loss = self.compute_contrastive_loss(feature_vectors, batch_size)\n",
    "            \n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        \n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        feature_vectors = self(inputs, training=False) \n",
    "        loss = self.compute_contrastive_loss(feature_vectors, batch_size)    \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        \n",
    "        return {'loss' : self.loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 11/118 [=>............................] - ETA: 40:57 - loss: 367.4523"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SEHWAN~1\\AppData\\Local\\Temp/ipykernel_38576/2177049382.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m hist = representation_learner.fit(\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder = create_encoder(representation_dim)\n",
    "\n",
    "representation_learner = RepresentationLearner(\n",
    "    encoder, projection_units, num_agumentation=2, temperature=0.1\n",
    ")\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=0.001, decay_steps=500, alpha=0.1\n",
    ")\n",
    "\n",
    "representation_learner.compile(\n",
    "    optimizer=tfa.optimizers.AdamW(learning_rate=lr_schedule,\n",
    "                                   weight_decay=0.0001)\n",
    ")\n",
    "\n",
    "hist = representation_learner.fit(\n",
    "    x = x_data, \n",
    "    batch_size=512, \n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ad7f8df95050390ccef3c53b91cc5366ee05cbbc975f965dd0a4e5b2556ae66"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
